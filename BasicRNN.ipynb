{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Applications\n",
    "- Time series predication\n",
    "- Language modeling (Text generation)\n",
    "- Text sentiment Analysis\n",
    "- Named entity recongnition\n",
    "- Translation\n",
    "- Speech recognition\n",
    "- Music Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define different cells using nn module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(4, 2, batch_first=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output is hidden_size\n",
    "cell = nn.RNN(input_size = 4, hidden_size = 2, batch_first = True)\n",
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(4, 2, batch_first=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = nn.LSTM(input_size = 4, hidden_size = 2, batch_first = True)\n",
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRU(4, 2, batch_first=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = nn.GRU(input_size = 4, hidden_size = 2, batch_first = True)\n",
    "cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs is (batch_size, seq_len, input_size) with batch_first = True \n",
    "# hidden is (num_layers, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed letters as inputs\n",
    "# One hot encoding\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size, seq_len, input_size\n",
    "inputs = torch.autograd.Variable(torch.Tensor([[h]]))\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_layers, batch_size, hidden_size (Initialize randome)\n",
    "hidden = torch.autograd.Variable(torch.randn(1, 1, 2))\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1223, 0.0739]]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[[0.1223, 0.0739]]], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "out , hidden = cell(inputs, hidden)\n",
    "# Expact two values as output \n",
    "print(out) \n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RNN for multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size, seq_len, input_size\n",
    "cell = nn.RNN(input_size = 4, hidden_size = 2, batch_first = True)\n",
    "inputs = torch.autograd.Variable(torch.Tensor([[h, e, l, l, o]]))\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9180,  0.6105],\n",
       "         [-0.9332, -0.1493],\n",
       "         [-0.8318, -0.4902],\n",
       "         [-0.7867, -0.3557],\n",
       "         [-0.9283,  0.5129]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_layers, batch_size, hidden_size (Initialize randome)\n",
    "hidden = torch.autograd.Variable(torch.randn(1, 1, 2))\n",
    "out , hidden = cell(inputs, hidden)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Multiple Batch input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size, seq_len, input_size\n",
    "cell = nn.RNN(input_size = 4, hidden_size = 2, batch_first = True)\n",
    "inputs = torch.autograd.Variable(torch.Tensor([[h, e, l, l, o],\n",
    "                                               [e, o, l, l, l],\n",
    "                                               [l, l, e, e, l]]))\n",
    "# Notice batch_first = True\n",
    "# batch_size = 3\n",
    "# seq_len = 5\n",
    "# input_size = 4\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3909, -0.8278],\n",
       "         [ 0.2668, -0.8183],\n",
       "         [ 0.7557, -0.8867],\n",
       "         [ 0.7022, -0.8637],\n",
       "         [ 0.2434, -0.5760]],\n",
       "\n",
       "        [[-0.6912, -0.9124],\n",
       "         [ 0.5885, -0.7042],\n",
       "         [ 0.6883, -0.8813],\n",
       "         [ 0.7109, -0.8668],\n",
       "         [ 0.7046, -0.8668]],\n",
       "\n",
       "        [[ 0.8152, -0.9416],\n",
       "         [ 0.7049, -0.8575],\n",
       "         [-0.0342, -0.7453],\n",
       "         [ 0.1342, -0.8053],\n",
       "         [ 0.7696, -0.8920]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_layers, batch_size, hidden_size (Initialize randome)\n",
    "hidden = torch.autograd.Variable(torch.randn(1, 3, 2))\n",
    "out , hidden = cell(inputs, hidden)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict the following sequence:\n",
    "- h --> i\n",
    "- i --> h\n",
    "- h --> e\n",
    "- e --> l\n",
    "- l --> l\n",
    "- l --> o\n",
    "\n",
    "There are five **input**  letters: h i e l  o \n",
    "\n",
    "There are fine **output** letters: h i e l  o \n",
    "\n",
    "Design our Loss function using **cross entropy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2char = ['h', 'i', 'e', 'l', 'o']\n",
    "h = [1, 0, 0, 0, 0]\n",
    "i = [0, 1, 0, 0, 0]\n",
    "e = [0, 0, 1, 0, 0]\n",
    "l = [0, 0, 0, 1, 0]\n",
    "o = [0, 0, 0, 0, 1]\n",
    "# teach hihell -> ihello\n",
    "x_data = [[0, 1, 0, 2, 3, 3]] #hihell\n",
    "x_one_hot = [[h, i, h, e, l, l]]\n",
    "y_data = [1, 0, 2, 3, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell = nn.RNN(input_size = 5, hidden_size = 5, batch_first = True)\n",
    "inputs = torch.autograd.Variable(torch.Tensor(x_one_hot))\n",
    "# Notice batch_first = True\n",
    "# batch_size = 1\n",
    "# seq_len = 6\n",
    "# input_size = 5\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_layers, batch_size, hidden_size (Initialize randome)\n",
    "hidden = torch.autograd.Variable(torch.LongTensor(y_data))\n",
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "input_size = 5\n",
    "hidden_size = 5\n",
    "batch_size = 1\n",
    "sequence_length = 1\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.view(batch_size, sequence_length, input_size)\n",
    "        out , hidden = self.rnncell(inputs, hidden)\n",
    "        # output should be 5 (num_classes)\n",
    "        out = out.view(-1, num_classes)\n",
    "        return hidden, out\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.autograd.Variable(torch.zeros(num_layers, batch_size, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
